{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Species Name] Occurrence Records Summary\n",
    "This notebook is a tool for exploring data sets requested from GBIF (and eventually other sources), and mostly for developing criteria for filtering records (filter sets).  When the entire notebook is run, it retrieves records according to the filter sets specified and saves the results (records and some summary tables) in an sqlite database.  Some information is pulled from the parameters.sqlite database that is saved in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables - fill out stuff in this cell.  \n",
    "Notes:\n",
    "default_coordUncertainty -- coordinateUncertaintyInMeters is often not provided.  Here is an option to use a default.  If you don't want anything entered, set this equal to False (boolean, not string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = ''\n",
    "summary_name = ''\n",
    "gbif_req_id = ''\n",
    "gbif_filter_id = ''\n",
    "default_coordUncertainty = 1000       # Note above.\n",
    "workDir = ''   # Be sure to create folders named \"Inputs\" and \"Outputs\" here.\n",
    "codeDir = ''\n",
    "paramdb = ''\n",
    "configDir = ''  # Path to folder where saved your wildlifeconfig file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bug with mpl_toolkits, the following code is a temp fix, hopefully.\n",
    "https://stackoverflow.com/questions/52911232/basemap-library-using-anaconda-jupyter-notebooks-keyerror-proj-lib/54087410#54087410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJ_LIB'] = r'c:\\Users\\nmtarr\\AppData\\Local\\Continuum\\miniconda3\\envs\\wrangler\\Library\\share'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - nothing to fill out in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.width', 600)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "from IPython.display import Image\n",
    "from pygbif import occurrences\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "t1 = datetime.now()\n",
    "import sys\n",
    "sys.path.append(configDir)\n",
    "import wranglerconfig as config\n",
    "sys.path.append(codeDir)\n",
    "import repo_functions as functions\n",
    "inDir = workDir + 'Inputs/'\n",
    "outDir = workDir + 'Outputs/'\n",
    "spdb = outDir + species_id + gbif_req_id + gbif_filter_id + '.sqlite'\n",
    "username = config.gbif_username\n",
    "password = config.gbif_password\n",
    "email = config.gbif_email\n",
    "print(\"Notebook run \" + str(t1))\n",
    "print(spdb)\n",
    "connjup = sqlite3.connect(paramdb)\n",
    "cursorjup = connjup.cursor()\n",
    "# Get some variables\n",
    "years = connjup.execute(\"\"\"SELECT years_range \n",
    "                           FROM gbif_requests WHERE request_id = '{0}'\"\"\".format(gbif_req_id)).fetchone()[0]\n",
    "gap_id = connjup.execute(\"\"\"SELECT gap_id\n",
    "                            FROM species_concepts WHERE species_id = '{0}'\"\"\".format(species_id)).fetchone()[0]\n",
    "common_name = connjup.execute(\"\"\"SELECT common_name\n",
    "                                 FROM species_concepts WHERE species_id = '{0}'\"\"\".format(species_id)).fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Concept\n",
    "Display information on the species from the parameters.sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = cursorjup.execute(\"SELECT * FROM species_concepts WHERE species_id = '{0}';\".format(species_id)).fetchall()[0]\n",
    "cols = [x[1] for x in cursorjup.execute(\"PRAGMA table_info('species_concepts')\").fetchall()]\n",
    "sp_dict = dict(zip(cols, vals))\n",
    "sp_df = pd.DataFrame.from_dict(sp_dict, orient='index', columns=['VALUE'])\n",
    "sp_df.index.name = 'ATTRIBUTE'\n",
    "print(\"SPECIES CONCEPT RECORD\")\n",
    "print(sp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    "Display the parameters of the request filter set.  These are deployed during the step where records are retrieved from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_df = pd.read_sql_query(sql=\"SELECT * FROM gbif_requests WHERE request_id = '{0}'\".format(gbif_req_id), con=connjup)\n",
    "print(\"THE REQUEST FILTER SET\")\n",
    "print(request_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the parameters of the post-request filter set.  These are deployed after the records are retrieved from the API, but before they are stored in the occurrence record sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = pd.read_sql_query(sql=\"SELECT * FROM gbif_filters WHERE filter_id = '{0}'\".format(gbif_filter_id), con=connjup)\n",
    "print(\"THE POST REQUEST FILTER SET\")\n",
    "print(filter_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter set justification - ENTER your justification for the following settings.\n",
    "\n",
    "**default_coord_uncertainty:** \n",
    "\n",
    "**years_range:**\n",
    "\n",
    "**months_range:** \n",
    "\n",
    "**geoissue:** \n",
    "\n",
    "**coordinate:** \n",
    "\n",
    "**country:**\n",
    "\n",
    "**geometry:**\n",
    "\n",
    "**collection_codes_omit:** \n",
    "\n",
    "**institutions_omit:** \n",
    "\n",
    "**datasets_omit:**\n",
    "\n",
    "**has_coordinate_uncertainty:** \n",
    "\n",
    "**max_coordinate_uncertainty:** \n",
    "\n",
    "**bases_omit:** \n",
    "\n",
    "**sampling_protocols_omit:** \n",
    "\n",
    "**issues_omit:**\n",
    "\n",
    "**duplicates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "functions.retrieve_gbif_occurrences(codeDir, species_id, inDir, paramdb, spdb, gbif_req_id, gbif_filter_id, \n",
    "                                    default_coordUncertainty, outDir, summary_name, username,\n",
    "                                   password, email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to output database, record species and filter info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_occ= sqlite3.connect(spdb)\n",
    "curs_occ = conn_occ.cursor()\n",
    "sp_df.to_sql(name='species_concept', con=conn_occ, if_exists='replace')\n",
    "request_df.to_sql(name=gbif_req_id, con=conn_occ, if_exists='replace')\n",
    "filter_df.to_sql(name=gbif_filter_id, con=conn_occ, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records made it through the filters?\n",
    "This is the number that was actually saved in the occurrence record sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_count = curs_occ.execute(\"SELECT COUNT(occ_id) FROM occurrences WHERE species_id = '{0}'\".format(species_id)).fetchone()\n",
    "print(str(record_count[0]) + \" records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = cursorjup.execute(\"SELECT table_name FROM table_descriptions\").fetchall()\n",
    "tables = [x[0] for x in tables]\n",
    "\n",
    "filter_sets = [gbif_req_id, gbif_filter_id]\n",
    "\n",
    "sources = []\n",
    "for s in filter_sets:\n",
    "    s = s.strip()\n",
    "    for tab in tables:\n",
    "        columns = cursorjup.execute(\"SELECT column_name FROM column_descriptions WHERE table_name = '{0}'\".format(tab)).fetchall()\n",
    "        columns = [x[0] for x in columns]\n",
    "        for col in columns:\n",
    "            try:\n",
    "                a = cursorjup.execute(\"SELECT source FROM {1} WHERE {2} = '{0}'\".format(s, tab, col)).fetchone()[0]\n",
    "                sources.append(a)\n",
    "            except:\n",
    "                pass\n",
    "print(list(set(sources))[0])\n",
    "\n",
    "sources = pd.read_sql(sql=\"SELECT * FROM pre_filter_source_counts;\", con=conn_occ)\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = cursorjup.execute(\"SELECT table_name FROM table_descriptions\").fetchall()\n",
    "tables = [x[0] for x in tables]\n",
    "\n",
    "filter_sets = [gbif_req_id, gbif_filter_id]\n",
    "\n",
    "sources = []\n",
    "for s in filter_sets:\n",
    "    s = s.strip()\n",
    "    for tab in tables:\n",
    "        columns = cursorjup.execute(\"SELECT column_name FROM column_descriptions WHERE table_name = '{0}'\".format(tab)).fetchall()\n",
    "        columns = [x[0] for x in columns]\n",
    "        for col in columns:\n",
    "            try:\n",
    "                a = cursorjup.execute(\"SELECT source FROM {1} WHERE {2} = '{0}'\".format(s, tab, col)).fetchone()[0]\n",
    "                sources.append(a)\n",
    "            except:\n",
    "                pass\n",
    "print(list(set(sources))[0])\n",
    "\n",
    "sql = \"SELECT institutionCode, collectionCode, datasetName, COUNT(occ_id) FROM occurrences GROUP BY institutionCode, collectionCode, datasetName;\"\n",
    "sources = pd.read_sql(sql=sql, con=conn_occ)\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bases\n",
    "#### Pre-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = pd.read_sql(sql=\"SELECT value as basisOfRecord, count FROM pre_filter_value_counts WHERE attribute = 'bases';\", con=conn_occ)\n",
    "print(bases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = \"SELECT basisOfRecord, COUNT(occ_id) as count FROM occurrences GROUP BY basisOfRecord;\"\n",
    "bases = pd.read_sql(sql=sql, con=conn_occ)\n",
    "print(bases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocols\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "protocol = pd.read_sql(sql=\"SELECT value as samplingProtocol, count FROM pre_filter_value_counts WHERE attribute = 'samplingProtocols';\", con=conn_occ)\n",
    "print(protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT samplingProtocol, COUNT(occ_id) as count FROM occurrences GROUP BY samplingProtocol;\"\n",
    "print(pd.read_sql(sql=sql, con=conn_occ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iss = pd.read_sql(sql=\"SELECT value as issues, count FROM pre_filter_value_counts WHERE attribute = 'issues';\", con=conn_occ)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "print(iss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = \"SELECT issues, COUNT(occ_id) as count FROM occurrences GROUP BY issues;\"\n",
    "print(pd.read_sql(sql=sql, con=conn_occ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions of filtered records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp1 = {'file': '{0}{1}_polygons'.format(outDir, summary_name), 'column': None,\n",
    "        'alias': 'Occurrence records', 'drawbounds': True, 'linewidth': .75, 'linecolor': 'k',\n",
    "        'fillcolor': None, 'marker':'o'}\n",
    "\n",
    "# Display occurrence polygons\n",
    "map_these=[shp1]\n",
    "    \n",
    "title=\"{1} ({0})\".format(years, common_name)\n",
    "functions.MapShapefilePolygons(map_these=map_these, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_years = [int(x[0]) for x in curs_occ.execute(\"SELECT strftime('%Y', occurrenceDate) FROM occurrences\").fetchall()]\n",
    "years = connjup.execute(\"SELECT years_range FROM gbif_requests WHERE request_id = '{0}'\".format(gbif_req_id)).fetchone()[0]\n",
    "years = years.split(',')\n",
    "yearsrng = list(range(int(years[0]), int(years[1]), 1))\n",
    "binsnum = int(years[1]) - int(years[0])\n",
    "plt.hist(occ_years, bins=binsnum)\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.xticks(yearsrng, rotation=90)\n",
    "plt.title(\"Occurrences per Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Months represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_months = [int(x[0]) for x in curs_occ.execute(\"SELECT strftime('%m', occurrenceDate) FROM occurrences\").fetchall()]\n",
    "plt.hist(occ_months, bins=range(1, 14), color=\"g\")\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"month\")\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title(\"Occurrences per Month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of coordinate uncertainty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "occ_cert = [int(x[0]) for x in curs_occ.execute(\"SELECT coordinateUncertaintyInMeters FROM occurrences\").fetchall()]\n",
    "maxi = np.max(occ_cert)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.hist(occ_cert, bins=50, color=\"r\")\n",
    "plt.xticks(range(0, maxi, int(maxi/50)), rotation=90)\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"coordinate uncertainty\")\n",
    "plt.title(\"Coordinate Uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_max = 2000\n",
    "occ_cert2 = [x for x in occ_cert if x <= rng_max]\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(occ_cert2, bins=30, color=\"m\", align='mid')\n",
    "plt.xticks(range(0, rng_max + 100, int(rng_max/30.)), rotation=90)\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"coordinate uncertainty\")\n",
    "plt.title(\"Coordinate Uncertainty - Zoomed In\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishment means reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishment = curs_occ.execute(\"SELECT vals FROM unique_values WHERE field = 'establishment' AND step = 'filter';\").fetchall()[0]\n",
    "for est in establishment:\n",
    "    est = est.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "    print(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification qualifiers included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali = curs_occ.execute(\"SELECT DISTINCT vals FROM unique_values WHERE field = 'IDqualifier' AND step = 'filter';\").fetchall()[0]\n",
    "for q in quali:\n",
    "    q = q.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remarks = curs_occ.execute(\"SELECT DISTINCT remarks FROM occurrences;\").fetchall()\n",
    "if len(remarks) <= 20:\n",
    "    try:\n",
    "        for rem in remarks:\n",
    "            if rem[0][0:1] == ';':\n",
    "                print(rem[0][2:])\n",
    "            else:\n",
    "                print(rem[0])\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"More than 20 remarks, consult the occurrence database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes returned for the records in the request (pre-filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields_summary = pd.read_sql(\"SELECT * FROM gbif_fields_returned\", conn_occ)#, index_col='index')\n",
    "fields_summary.index.name = 'Field'\n",
    "pd.set_option('display.max_rows', 250)\n",
    "print(fields_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = datetime.now()\n",
    "print(t2 - t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downy Woodpecker (invalid, old)\n",
    "This notebook is a tool for exploring data sets requested from GBIF (and eventually other sources), and mostly for developing criteria for filtering records (filter sets).  When the entire notebook is run, it retrieves records according to the filter sets specified and saves the results (records and some summary tables) in an sqlite database.  Some information is pulled from the parameters.sqlite database that is saved in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Variables - fill out stuff in this cell.  \n",
    "Notes:\n",
    "default_coordUncertainty -- coordinateUncertaintyInMeters is often not provided.  Here is an option to use a default.  If you don't want anything entered, set this equal to False (boolean, not string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_id = 'bdowox0'\n",
    "summary_name = 'bdowox1curr'\n",
    "gbif_req_id = 'GBIFr26'\n",
    "gbif_filter_id = 'GBIFf10'\n",
    "default_coordUncertainty = 1000       # Note above.\n",
    "workDir = 'T:/Occurrence_Records/'   # Be sure to create folders named \"Inputs\" and \"Outputs\" here.\n",
    "codeDir = 'T:/Code/wildlife-wrangler'\n",
    "paramdb = 'P:/Proj3/USGap/Vert/DBase/wildlife-wrangler.sqlite'\n",
    "configDir = 'T:/GAP/Data/'  # Path to folder where saved your wildlifeconfig file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a bug with mpl_toolkits, the following code is a temp fix, hopefully.\n",
    "https://stackoverflow.com/questions/52911232/basemap-library-using-anaconda-jupyter-notebooks-keyerror-proj-lib/54087410#54087410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PROJ_LIB'] = r'c:\\Users\\nmtarr\\AppData\\Local\\Continuum\\miniconda3\\envs\\wrangler\\Library\\share'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup - nothing to fill out in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook run 2020-04-08 10:50:31.949754\n",
      "T:/Occurrence_Records/Outputs/bdowox0GBIFr26GBIFf10.sqlite\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sqlite3\n",
    "import pprint\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.width', 600)\n",
    "pd.set_option('display.max_colwidth', 30)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "from IPython.display import Image\n",
    "from pygbif import occurrences\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "t1 = datetime.now()\n",
    "import sys\n",
    "sys.path.append(configDir)\n",
    "import wranglerconfig as config\n",
    "sys.path.append(codeDir)\n",
    "import wrangler_functions as functions\n",
    "inDir = workDir + 'Inputs/'\n",
    "outDir = workDir + 'Outputs/'\n",
    "spdb = outDir + species_id + gbif_req_id + gbif_filter_id + '.sqlite'\n",
    "username = config.gbif_username\n",
    "password = config.gbif_password\n",
    "email = config.gbif_email\n",
    "print(\"Notebook run \" + str(t1))\n",
    "print(spdb)\n",
    "connjup = sqlite3.connect(paramdb)\n",
    "cursorjup = connjup.cursor()\n",
    "# Get some variables\n",
    "years = connjup.execute(\"\"\"SELECT years_range \n",
    "                           FROM gbif_requests WHERE request_id = '{0}'\"\"\".format(gbif_req_id)).fetchone()[0]\n",
    "gap_id = connjup.execute(\"\"\"SELECT gap_id\n",
    "                            FROM species_concepts WHERE species_id = '{0}'\"\"\".format(species_id)).fetchone()[0]\n",
    "common_name = connjup.execute(\"\"\"SELECT common_name\n",
    "                                 FROM species_concepts WHERE species_id = '{0}'\"\"\".format(species_id)).fetchone()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Concept\n",
    "Display information on the species from the parameters.sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECIES CONCEPT RECORD\n",
      "                                        VALUE\n",
      "ATTRIBUTE                                    \n",
      "species_id                            bdowox0\n",
      "fws_id                                   None\n",
      "gap_id                                 bdowox\n",
      "itis_tsn                               178259\n",
      "gbif_id                               2477781\n",
      "bcb_id                                   None\n",
      "ebird_id                                 None\n",
      "common_name                  downy woodpecker\n",
      "scientific_name            Picoides pubescens\n",
      "start_year                               None\n",
      "split_from                               None\n",
      "end_year                                 2018\n",
      "lumped_into                           bdowox1\n",
      "geometry                                 None\n",
      "detection_distance_meters                 200\n",
      "vetted_how                 Consulted avibase.\n",
      "vetted_who                            N. Tarr\n",
      "vetted_date                         3/10/2020\n",
      "notes                                    None\n"
     ]
    }
   ],
   "source": [
    "vals = cursorjup.execute(\"SELECT * FROM species_concepts WHERE species_id = '{0}';\".format(species_id)).fetchall()[0]\n",
    "cols = [x[1] for x in cursorjup.execute(\"PRAGMA table_info('species_concepts')\").fetchall()]\n",
    "sp_dict = dict(zip(cols, vals))\n",
    "sp_df = pd.DataFrame.from_dict(sp_dict, orient='index', columns=['VALUE'])\n",
    "sp_df.index.name = 'ATTRIBUTE'\n",
    "print(\"SPECIES CONCEPT RECORD\")\n",
    "print(sp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters\n",
    "Display the parameters of the request filter set.  These are deployed during the step where records are retrieved from the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE REQUEST FILTER SET\n",
      "request_id                            GBIFr26\n",
      "source                                   GBIF\n",
      "lat_range                                None\n",
      "lon_range                                None\n",
      "years_range                         2000,2015\n",
      "months_range                             1,12\n",
      "geoissue                                False\n",
      "coordinate                               True\n",
      "country                                    US\n",
      "geometry                                 None\n",
      "creator                               N. Tarr\n",
      "notes           Built for GAP v2 range map...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "request_df = pd.read_sql_query(sql=\"SELECT * FROM gbif_requests WHERE request_id = '{0}'\".format(gbif_req_id), con=connjup)\n",
    "print(\"THE REQUEST FILTER SET\")\n",
    "print(request_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the parameters of the post-request filter set.  These are deployed after the records are retrieved from the API, but before they are stored in the occurrence record sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE POST REQUEST FILTER SET\n",
      "filter_id                                           GBIFf10\n",
      "dataset                                                GBIF\n",
      "institutions_omit                                      None\n",
      "collection_codes_omit                                  None\n",
      "datasets_omit                                          None\n",
      "has_coordinate_uncertainty                                0\n",
      "max_coordinate_uncertainty                             5000\n",
      "bases_omit                                  FOSSIL_SPECIMEN\n",
      "sampling_protocols_omit                                    \n",
      "issues_omit                             TYPE_STATUS_INVALID\n",
      "duplicates_OK                                         False\n",
      "creator                                             N. Tarr\n",
      "notes                         For use in creating GAP ve...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "filter_df = pd.read_sql_query(sql=\"SELECT * FROM gbif_filters WHERE filter_id = '{0}'\".format(gbif_filter_id), con=connjup)\n",
    "print(\"THE POST REQUEST FILTER SET\")\n",
    "print(filter_df.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter set justification - ENTER your justification for the following settings.\n",
    "\n",
    "**default_coord_uncertainty:** \n",
    "\n",
    "**years_range:**\n",
    "\n",
    "**months_range:** \n",
    "\n",
    "**geoissue:** \n",
    "\n",
    "**coordinate:** \n",
    "\n",
    "**country:**\n",
    "\n",
    "**geometry:**\n",
    "\n",
    "**collection_codes_omit:** \n",
    "\n",
    "**institutions_omit:** \n",
    "\n",
    "**datasets_omit:**\n",
    "\n",
    "**has_coordinate_uncertainty:** \n",
    "\n",
    "**max_coordinate_uncertainty:** \n",
    "\n",
    "**bases_omit:** \n",
    "\n",
    "**sampling_protocols_omit:** \n",
    "\n",
    "**issues_omit:**\n",
    "\n",
    "**duplicates:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPATIALITE_SECURITY set to relaxed\n",
      "Created occurrence db: 0:00:00.269721\n",
      "Got request params and sorted out geometry constraints: 0:00:00.002985\n",
      "239573 records available\n",
      "Your download key is  0037312-200221144449610\n",
      "Downloading Darwin Core Archive zip file for this species .....\n",
      "Download file size: 36895481 bytes\n",
      "On disk at T:/Occurrence_Records/Inputs//0037312-200221144449610.zip\n",
      "Download complete: 0:09:20.838203\n",
      "Downloaded and loaded records: 0:00:11.962532\n",
      "Summarized fields returned: 0:00:01.015316\n",
      "Created summary table of request results: 0:00:00.242636\n",
      "\tDEBUG ------------------------\n",
      "\n",
      " UNIQUE\n",
      "['GEODETIC_DATUM_ASSUMED_WGS84', 'COORDINATE_ROUNDED', '', 'COORDINATE_ROUNDED;GEODETIC_DATUM_ASSUMED_WGS84', 'COUNTRY_DERIVED_FROM_COORDINATES;GEODETIC_DATUM_ASSUMED_WGS84', 'COORDINATE_ROUNDED;GEODETIC_DATUM_ASSUMED_WGS84;GEODETIC_DATUM_INVALID', 'COORDINATE_ROUNDED;PRESUMED_NEGATED_LONGITUDE', 'COUNTRY_DERIVED_FROM_COORDINATES', 'COORDINATE_ROUNDED;COUNTRY_DERIVED_FROM_COORDINATES', 'GEODETIC_DATUM_ASSUMED_WGS84;COORDINATE_PRECISION_INVALID', 'COORDINATE_REPROJECTED']\n",
      "\n",
      " VIOLATIOnS\n",
      "[]\n",
      "Performed post-request filtering: 0:00:00.461015\n",
      "Calculated new columns, deleted some too: 0:00:00.405693\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ffd9c70487b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m functions.retrieve_gbif_occurrences(codeDir, species_id, inDir, paramdb, spdb, gbif_req_id, gbif_filter_id, \n\u001b[0;32m      2\u001b[0m                                     \u001b[0mdefault_coordUncertainty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutDir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummary_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musername\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                                    password, email)\n\u001b[0m",
      "\u001b[1;32mT:/Code/wildlife-wrangler\\wrangler_functions.py\u001b[0m in \u001b[0;36mretrieve_gbif_occurrences\u001b[1;34m(codeDir, species_id, inDir, paramdb, spdb, gbif_req_id, gbif_filter_id, default_coordUncertainty, outDir, summary_name, username, password, email)\u001b[0m\n\u001b[0;32m   1047\u001b[0m         \u001b[0mdf9\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf8\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DUPLICATES ON LATITUDE, LONGITUDE, DATE-TIME INCLUDED\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1049\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m     \u001b[1;31m###################################################  INSERT INTO DB (big)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mT:/Code/wildlife-wrangler\\wrangler_functions.py\u001b[0m in \u001b[0;36mdrop_duplicates_latlongdate\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mtrim_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dup_lonPlaces'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latitude'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'latitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrim_len\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'longitude'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'longitude'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrim_len\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;31m# Record the resulting precision for reference later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\wrangler\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\wrangler\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1026\u001b[0m                 \u001b[1;31m# scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m                     \u001b[0msetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "functions.retrieve_gbif_occurrences(codeDir, species_id, inDir, paramdb, spdb, gbif_req_id, gbif_filter_id, \n",
    "                                    default_coordUncertainty, outDir, summary_name, username,\n",
    "                                   password, email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to output database, record species and filter info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_occ= sqlite3.connect(spdb)\n",
    "curs_occ = conn_occ.cursor()\n",
    "sp_df.to_sql(name='species_concept', con=conn_occ, if_exists='replace')\n",
    "request_df.to_sql(name=gbif_req_id, con=conn_occ, if_exists='replace')\n",
    "filter_df.to_sql(name=gbif_filter_id, con=conn_occ, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many records made it through the filters?\n",
    "This is the number that was actually saved in the occurrence record sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_count = curs_occ.execute(\"SELECT COUNT(occ_id) FROM occurrences WHERE species_id = '{0}'\".format(species_id)).fetchone()\n",
    "print(str(record_count[0]) + \" records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there duplicate records left?\n",
    "NOTE:  DUPLICATE HANDLING MAY NOT BE PERFORMING CORRECTLY.  \n",
    "Duplicates based on latitude, longitude, and date-time should have been removed, with the record with the highest individualCount retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups0 = curs_occ.execute(\"\"\"SELECT count(occ_id) FROM occurrences WHERE occ_id NOT IN (SELECT occ_id FROM occurrences GROUP BY latitude, longitude, occurrenceDate HAVING max(IndividualCount));\"\"\").fetchall()\n",
    "print(str(dups0[0][0]) + ' duplicate records retained based on xy coordinate and date-time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = cursorjup.execute(\"SELECT table_name FROM table_descriptions\").fetchall()\n",
    "tables = [x[0] for x in tables]\n",
    "\n",
    "filter_sets = [gbif_req_id, gbif_filter_id]\n",
    "\n",
    "sources = []\n",
    "for s in filter_sets:\n",
    "    s = s.strip()\n",
    "    for tab in tables:\n",
    "        columns = cursorjup.execute(\"SELECT column_name FROM column_descriptions WHERE table_name = '{0}'\".format(tab)).fetchall()\n",
    "        columns = [x[0] for x in columns]\n",
    "        for col in columns:\n",
    "            try:\n",
    "                a = cursorjup.execute(\"SELECT source FROM {1} WHERE {2} = '{0}'\".format(s, tab, col)).fetchone()[0]\n",
    "                sources.append(a)\n",
    "            except:\n",
    "                pass\n",
    "print(list(set(sources))[0])\n",
    "\n",
    "sources = pd.read_sql(sql=\"SELECT * FROM pre_filter_source_counts;\", con=conn_occ)\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = cursorjup.execute(\"SELECT table_name FROM table_descriptions\").fetchall()\n",
    "tables = [x[0] for x in tables]\n",
    "\n",
    "filter_sets = [gbif_req_id, gbif_filter_id]\n",
    "\n",
    "sources = []\n",
    "for s in filter_sets:\n",
    "    s = s.strip()\n",
    "    for tab in tables:\n",
    "        columns = cursorjup.execute(\"SELECT column_name FROM column_descriptions WHERE table_name = '{0}'\".format(tab)).fetchall()\n",
    "        columns = [x[0] for x in columns]\n",
    "        for col in columns:\n",
    "            try:\n",
    "                a = cursorjup.execute(\"SELECT source FROM {1} WHERE {2} = '{0}'\".format(s, tab, col)).fetchone()[0]\n",
    "                sources.append(a)\n",
    "            except:\n",
    "                pass\n",
    "print(list(set(sources))[0])\n",
    "\n",
    "sql = \"SELECT institutionCode, collectionCode, datasetName, COUNT(occ_id) FROM occurrences GROUP BY institutionCode, collectionCode, datasetName;\"\n",
    "sources = pd.read_sql(sql=sql, con=conn_occ)\n",
    "print(sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bases\n",
    "#### Pre-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bases = pd.read_sql(sql=\"SELECT value as basisOfRecord, count FROM pre_filter_value_counts WHERE attribute = 'bases';\", con=conn_occ)\n",
    "print(bases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = \"SELECT basisOfRecord, COUNT(occ_id) as count FROM occurrences GROUP BY basisOfRecord;\"\n",
    "bases = pd.read_sql(sql=sql, con=conn_occ)\n",
    "print(bases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Protocols\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "protocol = pd.read_sql(sql=\"SELECT value as samplingProtocol, count FROM pre_filter_value_counts WHERE attribute = 'samplingProtocols';\", con=conn_occ)\n",
    "print(protocol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT samplingProtocol, COUNT(occ_id) as count FROM occurrences GROUP BY samplingProtocol;\"\n",
    "print(pd.read_sql(sql=sql, con=conn_occ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues\n",
    "#### Pre-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iss = pd.read_sql(sql=\"SELECT value as issues, count FROM pre_filter_value_counts WHERE attribute = 'issues';\", con=conn_occ)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "print(iss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sql = \"SELECT issues, COUNT(occ_id) as count FROM occurrences GROUP BY issues;\"\n",
    "print(pd.read_sql(sql=sql, con=conn_occ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptions of filtered records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp1 = {'file': '{0}{1}_polygons'.format(outDir, summary_name), 'column': None,\n",
    "        'alias': 'Occurrence records', 'drawbounds': True, 'linewidth': .75, 'linecolor': 'k',\n",
    "        'fillcolor': None, 'marker':'o'}\n",
    "\n",
    "# Display occurrence polygons\n",
    "map_these=[shp1]\n",
    "    \n",
    "title=\"{1} ({0})\".format(years, common_name)\n",
    "functions.MapShapefilePolygons(map_these=map_these, title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Years represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_years = [int(x[0]) for x in curs_occ.execute(\"SELECT strftime('%Y', occurrenceDate) FROM occurrences\").fetchall()]\n",
    "years = connjup.execute(\"SELECT years_range FROM gbif_requests WHERE request_id = '{0}'\".format(gbif_req_id)).fetchone()[0]\n",
    "years = years.split(',')\n",
    "yearsrng = list(range(int(years[0]), int(years[1]), 1))\n",
    "binsnum = int(years[1]) - int(years[0])\n",
    "plt.hist(occ_years, bins=binsnum)\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.xticks(yearsrng, rotation=90)\n",
    "plt.title(\"Occurrences per Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Months represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ_months = [int(x[0]) for x in curs_occ.execute(\"SELECT strftime('%m', occurrenceDate) FROM occurrences\").fetchall()]\n",
    "plt.hist(occ_months, bins=range(1, 14), color=\"g\")\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"month\")\n",
    "plt.xticks(range(1, 13))\n",
    "plt.title(\"Occurrences per Month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of coordinate uncertainty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "occ_cert = [int(x[0]) for x in curs_occ.execute(\"SELECT coordinateUncertaintyInMeters FROM occurrences\").fetchall()]\n",
    "maxi = np.max(occ_cert)\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.hist(occ_cert, bins=50, color=\"r\")\n",
    "plt.xticks(range(0, maxi, int(maxi/50)), rotation=90)\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"coordinate uncertainty\")\n",
    "plt.title(\"Coordinate Uncertainty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_max = 2000\n",
    "occ_cert2 = [x for x in occ_cert if x <= rng_max]\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.hist(occ_cert2, bins=30, color=\"m\", align='mid')\n",
    "plt.xticks(range(0, rng_max + 100, int(rng_max/30.)), rotation=90)\n",
    "plt.ylabel(\"number of records\")\n",
    "plt.xlabel(\"coordinate uncertainty\")\n",
    "plt.title(\"Coordinate Uncertainty - Zoomed In\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishment means reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishment = curs_occ.execute(\"SELECT vals FROM unique_values WHERE field = 'establishment' AND step = 'filter';\").fetchall()[0]\n",
    "for est in establishment:\n",
    "    est = est.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "    print(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identification qualifiers included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quali = curs_occ.execute(\"SELECT DISTINCT vals FROM unique_values WHERE field = 'IDqualifier' AND step = 'filter';\").fetchall()[0]\n",
    "for q in quali:\n",
    "    q = q.replace('[', '').strip().replace(']', '').replace(\"'\", \"\")\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remarks = curs_occ.execute(\"SELECT DISTINCT remarks FROM occurrences;\").fetchall()\n",
    "if len(remarks) <= 20:\n",
    "    try:\n",
    "        for rem in remarks:\n",
    "            if rem[0][0:1] == ';':\n",
    "                print(rem[0][2:])\n",
    "            else:\n",
    "                print(rem[0])\n",
    "    except:\n",
    "        pass\n",
    "else:\n",
    "    print(\"More than 20 remarks, consult the occurrence database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes returned for the records in the request (pre-filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fields_summary = pd.read_sql(\"SELECT * FROM gbif_fields_returned\", conn_occ)#, index_col='index')\n",
    "fields_summary.index.name = 'Field'\n",
    "pd.set_option('display.max_rows', 250)\n",
    "print(fields_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = datetime.now()\n",
    "print(t2 - t1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
